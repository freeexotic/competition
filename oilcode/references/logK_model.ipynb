{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, rdMolDescriptors\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='not removing hydrogen atom with dummy atom neighbors')\n",
    "\n",
    "\n",
    "def read(n: str, **kwargs):\n",
    "    return pl.read_csv(f\"../data/{n}\", **kwargs).to_pandas()\n",
    "\n",
    "\n",
    "data = read(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.919, SPLIT_SEED: 33161, MODEL_SEED: 43047\n"
     ]
    }
   ],
   "source": [
    "# 0.3\n",
    "# RMSE: 2.147, SPLIT_SEED: 27818, MODEL_SEED: 13700\n",
    "# RMSE: 2.107, SEED: 48362\n",
    "# RMSE: 2.789, SPLIT_SEED: 51225, MODEL_SEED: 78855\n",
    "# RMSE: 2.296, SPLIT_SEED: 43773, MODEL_SEED: 55376\n",
    "# 0.2\n",
    "# RMSE: 1.918, SPLIT_SEED: 24195, MODEL_SEED: 27886\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "scaler = StandardScaler()\n",
    "selector = SelectKBest(score_func=f_regression, k=100)\n",
    "\n",
    "split_seed = np.random.randint(0, 100000)\n",
    "model_seed = np.random.randint(0, 100000)\n",
    "\n",
    "def preprocess(\n",
    "    data: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "    data = data.copy()\n",
    "    data = data.dropna()\n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "    def compute_descriptors(smiles: str):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        features = {\n",
    "            \"MolLogP\": Descriptors.MolLogP(mol),\n",
    "            \"NumRotatableBonds\": rdMolDescriptors.CalcNumRotatableBonds(mol),\n",
    "            \"NumAromaticRings\": Descriptors.NumAromaticRings(mol),\n",
    "            \"NumSaturatedRings\": Descriptors.NumSaturatedRings(mol),\n",
    "            \"NumAtoms\": mol.GetNumAtoms(),\n",
    "            \"NumHeavyAtoms\": mol.GetNumHeavyAtoms(),\n",
    "            \"MolWt\": Descriptors.MolWt(mol),\n",
    "            \"TPSA\": Descriptors.TPSA(mol),\n",
    "            \"NumHAcceptors\": Descriptors.NumHAcceptors(mol),\n",
    "        }\n",
    "\n",
    "        morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "        morgan_fp_bits = np.array(list(morgan_fp.ToBitString())).astype(int)\n",
    "        for i, bit in enumerate(morgan_fp_bits):\n",
    "            features[f\"Bit_{i}\"] = bit\n",
    "\n",
    "        return features\n",
    "\n",
    "    descriptors_list = (\n",
    "        data[\"smiles\"].apply(compute_descriptors).dropna().tolist()\n",
    "    )\n",
    "    descriptors_df = pd.DataFrame.from_records(descriptors_list)\n",
    "\n",
    "    descriptors_df = descriptors_df.reset_index(drop=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    data = pd.concat([descriptors_df, data], axis=1)\n",
    "    data = data.drop(\"smiles\", axis=1)\n",
    "\n",
    "    if \"id\" in data.columns:\n",
    "        data = data.drop(\"id\", axis=1)\n",
    "\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    data_imputed = imputer.fit_transform(data[numeric_cols])\n",
    "\n",
    "    data = pd.DataFrame(data_imputed, columns=numeric_cols)\n",
    "\n",
    "    if \"logK\" in data.columns:\n",
    "        y = data.pop(\"logK\")\n",
    "        data = scaler.fit_transform(data, y)\n",
    "        data = selector.fit_transform(data, y)\n",
    "        return data, y\n",
    "\n",
    "    data = scaler.transform(data)\n",
    "    data = selector.transform(data)\n",
    "    return data, None\n",
    "\n",
    "\n",
    "X, y = preprocess(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=split_seed)\n",
    "\n",
    "# X_train, y_train = preprocess(train)\n",
    "\n",
    "# check = test.copy()\n",
    "# y_test = test.pop(\"logK\")\n",
    "# X_test, _ = preprocess(check)\n",
    "\n",
    "# train_pool = Pool(X_train, y_train)\n",
    "# test_pool = Pool(X_test, y_test)\n",
    "\n",
    "model = ExtraTreesRegressor(random_state=model_seed)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RMSE: {rmse:.3f}, SPLIT_SEED: {split_seed}, MODEL_SEED: {model_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"../models/30pS_ETR_2.296_logk.joblib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.052109\n",
      "0:\tlearn: 6.1475510\ttest: 5.0978660\tbest: 5.0978660 (0)\ttotal: 15.5ms\tremaining: 15.5s\n",
      "bestTest = 3.000267424\n",
      "bestIteration = 55\n",
      "Shrink model to first 56 iterations.\n",
      "Root Mean Squared Error (RMSE): 3.0002667463224255\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    task_type=\"GPU\",\n",
    "    devices=\"0\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(train_pool, verbose=100, eval_set=test_pool, early_stopping_rounds=20)\n",
    "\n",
    "predictions = model.predict(test_pool)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = mse**0.5\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"../models/best_model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.462, SEED: 1635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "model = ExtraTreesRegressor(random_state=seed)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RMSE: {rmse:.3f}, SEED: {seed}\")\n",
    "# RMSE: 1.788, SEED: 8779\n",
    "# RMSE: 1.731, SEED: 61821\n",
    "# RMSE: 1.723, SEED: 61311\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"../models/ETR_logK.joblib\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best params: {'tol': 0.001, 'max_iter': 100, 'alpha': 1.0}\n",
      "RMSE: 2.786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import GammaRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Определение модели\n",
    "model = GammaRegressor()\n",
    "\n",
    "# Сетка гиперпараметров для тестирования\n",
    "param_distributions = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],  # Регуляризация\n",
    "    'max_iter': [100, 200, 300, 500],  # Максимальное количество итераций\n",
    "    'tol': [1e-3, 1e-4, 1e-5],  # Точность решения\n",
    "}\n",
    "\n",
    "# Настройка RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Обучение RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Вывод лучших параметров\n",
    "print(\"Best params:\", random_search.best_params_)\n",
    "\n",
    "# Использование лучшей модели для предсказаний\n",
    "best_model = random_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Расчет RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:02<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 306\n",
      "[LightGBM] [Info] Number of data points in the train set: 172, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 9.227965\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>2.78</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GammaRegressor</th>\n",
       "      <td>2.78</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>2.79</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>2.80</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>2.82</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>2.86</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>2.87</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>2.89</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>2.91</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>2.99</td>\n",
       "      <td>-0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>3.02</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>3.03</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>3.05</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>3.17</td>\n",
       "      <td>-0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>3.21</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>3.24</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>3.24</td>\n",
       "      <td>-0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>3.28</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>3.29</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>3.32</td>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>3.32</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>3.36</td>\n",
       "      <td>-0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>3.46</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>3.48</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>3.51</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>3.53</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>3.56</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>3.57</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>3.58</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>3.89</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>3.95</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>4.19</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>4.45</td>\n",
       "      <td>-1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>4.73</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>4.84</td>\n",
       "      <td>-1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>6.36</td>\n",
       "      <td>-2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>9.57</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>1481152463248.58</td>\n",
       "      <td>1333999346726.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>1481152463248.58</td>\n",
       "      <td>1333999346726.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>7502833998788.70</td>\n",
       "      <td>7502833998785.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>44573018616113.23</td>\n",
       "      <td>38160271512363.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>122173192936880716382208.00</td>\n",
       "      <td>122172417393460464582656.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     RMSE  \\\n",
       "Model                                                       \n",
       "LassoCV                                              2.78   \n",
       "GammaRegressor                                       2.78   \n",
       "ElasticNetCV                                         2.79   \n",
       "TweedieRegressor                                     2.80   \n",
       "BayesianRidge                                        2.82   \n",
       "RidgeCV                                              2.86   \n",
       "ExtraTreesRegressor                                  2.87   \n",
       "SGDRegressor                                         2.89   \n",
       "KNeighborsRegressor                                  2.91   \n",
       "MLPRegressor                                         2.99   \n",
       "PoissonRegressor                                     3.02   \n",
       "ElasticNet                                           3.03   \n",
       "SVR                                                  3.05   \n",
       "Ridge                                                3.17   \n",
       "NuSVR                                                3.21   \n",
       "RandomForestRegressor                                3.24   \n",
       "LinearSVR                                            3.24   \n",
       "LassoLarsIC                                          3.28   \n",
       "AdaBoostRegressor                                    3.29   \n",
       "Lasso                                                3.32   \n",
       "LassoLars                                            3.32   \n",
       "HuberRegressor                                       3.36   \n",
       "OrthogonalMatchingPursuitCV                          3.46   \n",
       "OrthogonalMatchingPursuit                            3.48   \n",
       "GradientBoostingRegressor                            3.51   \n",
       "BaggingRegressor                                     3.53   \n",
       "HistGradientBoostingRegressor                        3.56   \n",
       "PassiveAggressiveRegressor                           3.57   \n",
       "LGBMRegressor                                        3.58   \n",
       "LarsCV                                               3.89   \n",
       "XGBRegressor                                         3.95   \n",
       "ExtraTreeRegressor                                   4.19   \n",
       "QuantileRegressor                                    4.45   \n",
       "DecisionTreeRegressor                                4.73   \n",
       "DummyRegressor                                       4.84   \n",
       "GaussianProcessRegressor                             6.36   \n",
       "KernelRidge                                          9.57   \n",
       "LinearRegression                         1481152463248.58   \n",
       "TransformedTargetRegressor               1481152463248.58   \n",
       "LassoLarsCV                              7502833998788.70   \n",
       "RANSACRegressor                         44573018616113.23   \n",
       "Lars                          122173192936880716382208.00   \n",
       "\n",
       "                                                RMSE_diff  \n",
       "Model                                                      \n",
       "LassoCV                                             -0.13  \n",
       "GammaRegressor                                      -0.20  \n",
       "ElasticNetCV                                         0.04  \n",
       "TweedieRegressor                                     0.13  \n",
       "BayesianRidge                                        0.10  \n",
       "RidgeCV                                             -0.13  \n",
       "ExtraTreesRegressor                                  1.04  \n",
       "SGDRegressor                                        -0.41  \n",
       "KNeighborsRegressor                                  0.10  \n",
       "MLPRegressor                                        -0.38  \n",
       "PoissonRegressor                                    -0.25  \n",
       "ElasticNet                                          -0.18  \n",
       "SVR                                                 -0.64  \n",
       "Ridge                                               -0.65  \n",
       "NuSVR                                               -0.67  \n",
       "RandomForestRegressor                                0.49  \n",
       "LinearSVR                                           -0.59  \n",
       "LassoLarsIC                                          0.26  \n",
       "AdaBoostRegressor                                   -0.12  \n",
       "Lasso                                               -0.43  \n",
       "LassoLars                                           -0.44  \n",
       "HuberRegressor                                      -0.97  \n",
       "OrthogonalMatchingPursuitCV                          0.16  \n",
       "OrthogonalMatchingPursuit                            0.18  \n",
       "GradientBoostingRegressor                            0.38  \n",
       "BaggingRegressor                                     0.68  \n",
       "HistGradientBoostingRegressor                        0.46  \n",
       "PassiveAggressiveRegressor                          -0.41  \n",
       "LGBMRegressor                                        0.27  \n",
       "LarsCV                                               0.03  \n",
       "XGBRegressor                                         0.87  \n",
       "ExtraTreeRegressor                                   0.59  \n",
       "QuantileRegressor                                   -1.56  \n",
       "DecisionTreeRegressor                                0.22  \n",
       "DummyRegressor                                      -1.08  \n",
       "GaussianProcessRegressor                            -2.67  \n",
       "KernelRidge                                          0.17  \n",
       "LinearRegression                         1333999346726.31  \n",
       "TransformedTargetRegressor               1333999346726.31  \n",
       "LassoLarsCV                              7502833998785.67  \n",
       "RANSACRegressor                         38160271512363.81  \n",
       "Lars                          122172417393460464582656.00  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=rmse)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "rmse_history.append(models[\"RMSE\"])\n",
    "\n",
    "models_df = models.sort_values(\"RMSE\")\n",
    "if len(rmse_history) > 1:\n",
    "    models_df[\"RMSE_diff\"] = rmse_history[-1] - rmse_history[-2]\n",
    "else:\n",
    "    models_df[\"RMSE_diff\"] = np.nan\n",
    "\n",
    "models_df[[\"RMSE\", \"RMSE_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import rdMolDescriptors, GetSSSR\n",
    "\n",
    "smiles = \"O=C(O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO\"\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "len(GetSSSR(mol)), mol.GetNumHeavyAtoms(), mol.GetNumAtoms(), rdMolDescriptors.CalcNumRotatableBonds(mol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-chemistry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
